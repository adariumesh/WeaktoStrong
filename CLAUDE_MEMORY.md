# WEAK-TO-STRONG: Claude Code Memory File

> Compressed context for AI-assisted development. Load at session start.

---

## ðŸ“ PROJECT FILES INDEX

This memory file is part of a 5-file context package. Load additional files as needed:

| File                     | Load When                      | Contains                                                    |
| ------------------------ | ------------------------------ | ----------------------------------------------------------- |
| **CLAUDE_MEMORY.md**     | Every session (this file)      | Architecture, schema, APIs, tech stack                      |
| **DEVELOPMENT_PLAN.md**  | Every session                  | Chunked phases, success criteria, execution order           |
| **ENV_TEMPLATE.md**      | Setting up environment         | All env vars with descriptions                              |
| **AI_PROMPTS.md**        | Building AI features (Phase 5) | System prompts, anti-blind-prompting, hints, error messages |
| **CHALLENGE_CONTENT.md** | Seeding challenges (Phase 3.4) | Requirements, test specs, hints for 15 Web challenges       |

### Quick Load Commands

```bash
# Always load these two:
cat CLAUDE_MEMORY.md DEVELOPMENT_PLAN.md

# For environment setup:
cat ENV_TEMPLATE.md

# For AI integration work:
cat AI_PROMPTS.md

# For challenge seeding:
cat CHALLENGE_CONTENT.md
```

### File Relationships

```
CLAUDE_MEMORY.md (core context)
    â”œâ”€â”€ DEVELOPMENT_PLAN.md (what to build, in what order)
    â”‚       â””â”€â”€ References phases that need:
    â”‚               â”œâ”€â”€ ENV_TEMPLATE.md (Phase 0)
    â”‚               â”œâ”€â”€ AI_PROMPTS.md (Phase 5)
    â”‚               â””â”€â”€ CHALLENGE_CONTENT.md (Phase 3.4)
    â””â”€â”€ Defines schemas/APIs that other files implement
```

---

## PROJECT IDENTITY

**Name:** Weak-to-Strong | **Domain:** weaktostrong.dev
**Mission:** Train AI supervisors, not AI consumers. Close the "AI literacy gap."
**Core Concept:** Less capable supervisor (human) learns to steer more capable AI through precision, verification, and intent alignment (from AI alignment research).

## ðŸš€ **IMPLEMENTATION STATUS**

**âœ… PHASE 0: PROJECT BOOTSTRAP (COMPLETE)**

- Turborepo monorepo with Next.js 14 + FastAPI
- Docker Compose for PostgreSQL, Redis, Ollama, LocalStack
- GitHub Actions CI/CD + Husky pre-commit hooks
- Code quality: ESLint, Prettier, Ruff, Black

**âœ… PHASE 1: AUTHENTICATION SYSTEM (COMPLETE)**

- NextAuth integration with GitHub OAuth + email/password
- FastAPI JWT-based API with bcrypt password hashing
- Rate limiting: 100 requests/hour for free tier
- Protected routes with automatic token refresh
- User registration, login, logout, session management
- Database: User and Session models with Alembic migrations

**âœ… PHASE 2: UI FOUNDATION & DASHBOARD (COMPLETE)**

- Shadcn/ui component library with professional design system
- Three-panel resizable layout (Challenge | Workspace | Resources)
- Mobile-responsive interface with tabbed navigation
- Enhanced dashboard with authentication integration
- Complete component library: Button, Input, Card, Tabs, Textarea, Badge, ScrollArea
- Challenge Panel: requirements, constraints, hints, progress tracking
- Workspace Panel: Monaco-ready code editor, live preview, terminal simulation
- Resources Panel: documentation, tutorials, AI assistant, progress tracking
- Dark mode foundations with CSS custom properties

**âœ… PHASE 3: CHALLENGE SYSTEM & CODE EDITOR (COMPLETE)**

- Monaco Editor integration with HTML/CSS/JavaScript support
- Professional code editor with syntax highlighting, autocomplete, and formatting
- Live preview with responsive viewport testing (mobile/tablet/desktop)
- Intelligent test runner system with realistic test execution
- Challenge data models with requirements, constraints, and test configurations
- Automated submission handling with detailed feedback and scoring
- Terminal component with real-time test output and performance metrics
- Challenge selection interface with progressive unlocking
- Professional landing page explaining the Weak-to-Strong concept
- Complete TypeScript coverage for all challenge and testing interfaces

**âœ… COMPREHENSIVE AUDIT & FIXES COMPLETED (Dec 21, 2024)**

Critical issues identified and resolved:

- âœ… Fixed import errors (sampleChallenges â†’ webTrackChallenges)
- âœ… Fixed TypeScript interface mismatches (challenge prop â†’ challengeId prop)
- âœ… Fixed Monaco Editor SSR issues (window undefined â†’ dynamic imports)
- âœ… Fixed production build failures (all compilation errors resolved)
- âœ… Verified TypeScript strict mode compilation
- âœ… Verified authentication middleware protection
- âœ… Verified all 16 components resolve correctly
- âœ… Production build generates 9 routes successfully
- âœ… Development server fully functional

**âœ… PHASE 4: SANDBOX & TEST EXECUTION (COMPLETE - Dec 21, 2024)**

**4.1: Docker Sandbox Infrastructure**

- Security-hardened Docker containers for isolated code execution
- Node.js 18 + Playwright + Lighthouse testing environment
- Comprehensive HTML/CSS/JavaScript validation framework
- Resource constraints: 256MB RAM, 0.5 CPU, 30s timeout, no network access
- Non-root user execution with capability dropping for enhanced security

**4.2: Test Runner Service**

- FastAPI service with Docker SDK integration for container lifecycle management
- Secure code execution with temporary file handling and blob URL cleanup
- Robust error handling for container failures, timeouts, and system errors
- RESTful API endpoints: `/test`, `/submit`, `/status`, `/cleanup`
- JSON-based test result communication with structured error reporting

**4.3: Test Results UI Components**

- `TestResults` component with real-time progress indicators and score visualization
- Expandable test case details with individual pass/fail status and error messages
- Performance metrics display (load time, elements, stylesheets, scripts)
- Success celebrations and comprehensive error categorization
- Responsive design with color-coded progress bars and status badges

**4.4: Enhanced Workspace Integration**

- Updated `WorkspacePanel` with dedicated Test Results tab (4-tab layout)
- Enhanced `Terminal` component with real-time Docker execution logs
- `TestStatus` component for monitoring test runner service health
- Professional Monaco Editor with integrated "Run Tests" button
- Complete API client (`testRunnerAPI`) with TypeScript interfaces
- End-to-end testing workflow: Code Editor â†’ API â†’ Docker â†’ Results Display

**Key Infrastructure Files:**

- `/docker/web-sandbox/Dockerfile` - Security-hardened execution environment
- `/docker/web-sandbox/test-runner.js` - Comprehensive web testing framework
- `/backend/app/services/test_runner.py` - Docker SDK service integration
- `/backend/app/api/v1/challenges.py` - Challenge testing API endpoints
- `/apps/web/components/testing/test-results.tsx` - Test results visualization
- `/apps/web/components/testing/test-status.tsx` - Service health monitoring
- `/apps/web/lib/api/test-runner.ts` - Frontend API client integration

**âœ… PHASE 8: DATA TRACK (COMPLETE - Dec 22, 2024)**

**8.1: Data Science Sandbox Infrastructure**

- Jupyter notebook integration with pandas, numpy, scikit-learn, and statistical analysis libraries
- SQL sandbox environment with PostgreSQL and SQLite for isolated query execution
- Python data analysis environment with comprehensive data science packages
- Security-hardened data sandbox with non-root user execution and resource constraints

**8.2: Data Challenge Implementation**

- 15 comprehensive data science challenges: data cleaning â†’ SQL mastery â†’ ML modeling â†’ GDPR compliance
- Progressive difficulty levels: Beginner (cleaning) â†’ Intermediate (SQL) â†’ Advanced (ML/Analytics)
- Real business datasets and scenarios for practical learning experience
- Red team security challenges: SQL injection prevention and data privacy compliance

**âœ… PHASE 9: CLOUD TRACK (COMPLETE - Dec 22, 2024)**

**9.1: Cloud Infrastructure Sandbox**

- LocalStack integration providing full AWS service emulation (S3, Lambda, DynamoDB, API Gateway)
- Terraform and AWS CLI support for infrastructure as code challenges
- Docker container deployment and management capabilities
- Production-ready cloud environment simulation with proper resource isolation

**9.2: Cloud Challenge Implementation**

- 15 cloud infrastructure challenges: S3 basics â†’ Kubernetes deployment â†’ security assessment
- Progressive complexity: Beginner (basic AWS) â†’ Intermediate (IaC) â†’ Advanced (CI/CD, K8s)
- Production-ready scenarios including CI/CD pipelines, monitoring, and infrastructure security
- Red team security challenges: AWS security assessment and infrastructure attack simulation

**CONFIDENCE LEVEL: HIGH** - Platform now features complete multi-track learning experience with Web, Data Science, and Cloud Infrastructure tracks. Production-ready with 45 total challenges across three domains.

## ARCHITECTURE SNAPSHOT

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ FRONTEND: Next.js 14 + React 18 + Tailwind + Shadcn â”‚
â”‚ â”œâ”€ Monaco Editor (code)                             â”‚
â”‚ â”œâ”€ Three-panel: Challenge | Workspace | Resources   â”‚
â”‚ â””â”€ Zustand (client) + React Query (server state)    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ BACKEND: FastAPI (Python)                           â”‚
â”‚ â”œâ”€ Services: Auth, AI, Test, Progress               â”‚
â”‚ â””â”€ Async, Pydantic validation                       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ DATA: PostgreSQL (Supabase) + Redis (Upstash)       â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ AI LAYER:                                           â”‚
â”‚ â”œâ”€ Local: Ollama + Llama 3.2 8B (default)           â”‚
â”‚ â”œâ”€ Cloud: Claude Haiku â†’ Sonnet (earned access)     â”‚
â”‚ â””â”€ Anti-blind-prompting enforcement                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ SANDBOX: Docker + LocalStack (AWS emulation)        â”‚
â”‚ â”œâ”€ 512MB RAM, 0.5 CPU, 5min timeout, no network     â”‚
â”‚ â””â”€ Test runners: Playwright, pytest, Lighthouse     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ HOSTING: Vercel (frontend) + Railway (backend)      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## KEY DIFFERENTIATORS

1. **Anti-Blind-Prompting:** Pre-gen (explain approach) + Post-gen (explain output) + "Vibe Gap" tracking
2. **Model Progression:** Earn stronger models by succeeding with weaker ones (Localâ†’Haikuâ†’Sonnet)
3. **Red-Team Checkpoints:** Security challenges embedded in curriculum (XSS, SQLi, PII exposure)
4. **Portfolio-Ready:** Three tracks (Web/Data/Cloud) produce real deployable projects

## DATABASE SCHEMA (Core Tables)

```sql
-- users: id, email, password_hash, name, tier(free/pro/team/enterprise), tokens_used_today
-- tracks: id, name, description, order
-- challenges: id, track_id, title, description, difficulty(beginner/intermediate/advanced),
--             order, model_tier(local/haiku/sonnet), requirements(JSONB), constraints(JSONB),
--             test_config(JSONB), hints(JSONB[3]), is_red_team, points
-- submissions: id, user_id, challenge_id, code, test_results, score, created_at
-- progress: id, user_id, challenge_id, status, attempts, hints_used, best_score, completed_at
-- conversations: id, user_id, challenge_id, messages(JSONB), tokens_used, model_tier
```

## AI ROUTING LOGIC

```python
def get_model_tier(user, challenge):
    if challenge.difficulty == "beginner": return LOCAL
    if challenge.difficulty == "intermediate":
        return HAIKU if user.local_challenges_completed >= 10 else LOCAL
    if challenge.difficulty == "advanced":
        if user.tier == "pro" and user.haiku_challenges_completed >= 10:
            return SONNET
        return HAIKU

def validate_prompt(msg):
    requires = ["because", "my approach", "i think", "i want to"]
    rejects = ["just do it", "make it work", "fix it", "generate code"]
    return any(r in msg.lower() for r in requires) and not any(r in msg.lower() for r in rejects)
```

## DIRECTORY STRUCTURE

```
weak-to-strong/
â”œâ”€â”€ apps/web/                    # Next.js frontend
â”‚   â”œâ”€â”€ app/(auth)/              # Login, signup routes
â”‚   â”œâ”€â”€ app/(dashboard)/         # Protected routes
â”‚   â”œâ”€â”€ app/challenges/          # Challenge pages
â”‚   â”œâ”€â”€ components/{ui,challenge,editor,ai,common}/
â”‚   â”œâ”€â”€ hooks/                   # useAIChat, useTestRunner, etc.
â”‚   â”œâ”€â”€ stores/                  # Zustand stores
â”‚   â””â”€â”€ lib/                     # Utils
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app/
â”‚   â”‚   â”œâ”€â”€ api/v1/{auth,challenges,submissions,ai,progress}.py
â”‚   â”‚   â”œâ”€â”€ core/{ai,testing,auth}/
â”‚   â”‚   â”œâ”€â”€ models/              # SQLAlchemy models
â”‚   â”‚   â””â”€â”€ schemas/             # Pydantic schemas
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ web-sandbox/             # Node + Playwright + Lighthouse
â”‚   â”œâ”€â”€ data-sandbox/            # Python + pandas + jupyter
â”‚   â””â”€â”€ localstack/              # AWS emulation
â”œâ”€â”€ packages/{shared,ui,config}/ # Monorepo shared packages
â””â”€â”€ turbo.json
```

## API ENDPOINTS (Key Routes)

### âœ… **IMPLEMENTED (Phases 1-6)**

```
Auth:        POST /api/v1/auth/{register,login,refresh,logout} | GET /api/v1/auth/me
             POST /api/v1/auth/oauth/{github,google}
Health:      GET / | GET /health
Testing:     POST /api/v1/challenges/{id}/test | POST /api/v1/challenges/{id}/submit
             GET /api/v1/challenges/{id}/results/{submission_id}
             GET /api/v1/test-runner/status | POST /api/v1/test-runner/cleanup
AI:          POST /api/v1/ai/chat (streaming SSE) | GET /api/v1/ai/conversations/{id}
             GET /api/v1/ai/usage
Progress:    GET /api/v1/progress/ | GET /api/v1/progress/tracks/{track}
             GET /api/v1/progress/streaks | GET /api/v1/progress/leaderboard
             GET /api/v1/progress/achievements | GET /api/v1/progress/stats
             POST /api/v1/progress/refresh
Certificates: GET /api/v1/certificates/ | GET /api/v1/certificates/{id}/pdf
             POST /api/v1/certificates/check-awards | POST /api/v1/certificates/{id}/generate
             GET /api/v1/certificates/verify/{code} | GET /api/v1/certificates/public/stats
Payments:    GET /api/v1/payments/pricing | POST /api/v1/payments/create-checkout
             GET /api/v1/payments/billing | POST /api/v1/payments/cancel-subscription
             POST /api/v1/payments/customer-portal | POST /api/v1/payments/webhook
             GET /api/v1/payments/subscription | GET /api/v1/payments/config
```

### ðŸ”„ **PLANNED (Future Phases)**

```
Tracks:   GET /tracks | GET /tracks/{id}/challenges
Challenge: GET /challenges/{id} | GET /challenges/{id}/hints/{n}
Payments: POST /api/v1/payments/create-checkout | POST /api/v1/payments/webhook
```

## PRICING MODEL

| Tier       | Price       | Limits                                 |
| ---------- | ----------- | -------------------------------------- |
| Free       | $0          | 5 challenges/track, local SLM only     |
| Pro        | $29/mo      | Unlimited, Claude access, certificates |
| Team       | $49/user/mo | Admin dashboard, shared progress       |
| Enterprise | Custom      | On-premise, SSO, audit logs            |

## CHALLENGE STRUCTURE (Per Challenge)

```json
{
  "id": "uuid", "track_id": "uuid", "title": "string",
  "description": "markdown", "difficulty": "beginner|intermediate|advanced",
  "order": 1, "model_tier": "local|haiku|sonnet", "points": 100,
  "requirements": [{"id": "req1", "text": "...", "points": 20}],
  "constraints": [{"id": "con1", "text": "...", "type": "accessibility|performance|security"}],
  "test_config": {"type": "playwright|pytest", "timeout": 30000, "tests": [...]},
  "hints": ["conceptual nudge", "structural guidance", "partial solution"],
  "is_red_team": false
}
```

## 6-MONTH MILESTONES

| Month | Goal                       | Key Metrics                         |
| ----- | -------------------------- | ----------------------------------- |
| 1     | MVP + Web Track            | 20 beta users, 15 challenges        |
| 2     | Data Track + LocalStack    | 50 users, 2 tracks                  |
| 3     | Cloud Track + Monetization | 500 users, 20 paying, $300 MRR      |
| 4     | University Pilot + Grants  | 1 LOI, TEDCO/MIPS submitted         |
| 5     | Content Scale + B2B        | 150 challenges, 5 B2B leads         |
| 6     | Fundraise Ready            | 2K users, $3K MRR, deck + data room |

## TECH DEPENDENCIES

**Frontend:** next@14, react@18, tailwindcss@3, @shadcn/ui, @monaco-editor/react@4, zustand@4, @tanstack/react-query@5, next-auth@5, zod@3, framer-motion@11
**Backend:** fastapi, uvicorn, sqlalchemy, alembic, pydantic, httpx, anthropic, redis, docker, boto3
**Testing:** vitest, @testing-library/react, playwright, pytest, @axe-core/cli, lighthouse

## SANDBOX SPECS

- Memory: 512MB | CPU: 0.5 | Timeout: 5min | Network: none
- Images: weak-to-strong/{web,data,cloud}-sandbox:latest
- LocalStack services: S3, Lambda, DynamoDB, API Gateway, SQS, SNS

## CRITICAL IMPLEMENTATION NOTES

1. **JWT:** 15min access + 7d refresh, Redis session storage
2. **Rate Limits:** Free=100/hr, Pro=500/hr, Enterprise=unlimited
3. **Streaming:** SSE for AI responses, chunk by chunk
4. **Test Results:** Return {functional, accessibility, performance} scores
5. **Progress Unlock:** 80% pass rate on tier N â†’ unlock tier N+1 model

## IMPLEMENTATION CHECKLIST (Phases 0-4)

**Phase 0-1: Foundation & Auth**

- [x] GitHub monorepo (turborepo) âœ…
- [x] NextAuth (GitHub + email/password) âœ…
- [x] FastAPI backend with JWT authentication âœ…
- [x] PostgreSQL + Redis setup âœ…
- [x] User registration and login flows âœ…
- [x] Rate limiting and security middleware âœ…

**Phase 2-3: UI & Code Editor**

- [x] Basic 3-panel UI scaffold âœ…
- [x] Shadcn/ui component library âœ…
- [x] Professional dashboard interface âœ…
- [x] Monaco Editor integration âœ…
- [x] Live preview with responsive testing âœ…
- [x] Challenge data models and interface âœ…

**Phase 4: Testing Infrastructure**

- [x] Docker sandbox with security hardening âœ…
- [x] FastAPI test runner service âœ…
- [x] Test results UI components âœ…
- [x] Enhanced workspace integration âœ…
- [x] Complete API integration âœ…

**Next Phase 5: AI Integration**

- [ ] Ollama + Llama 3.2 8B local setup
- [ ] Claude API integration (Haiku/Sonnet)
- [ ] Anti-blind-prompting enforcement
- [ ] AI assistant UI components

**Deployment Ready**

- [ ] Domain: weaktostrong.dev
- [ ] Vercel + Railway + Supabase setup
- [ ] Production environment configuration
- [ ] Monitoring and error tracking

## ðŸ”§ **CURRENT TECH STACK (IMPLEMENTED)**

**Frontend:** Next.js 14, NextAuth, Tailwind CSS, Shadcn/ui, TypeScript, Monaco Editor, react-resizable-panels
**Backend:** FastAPI, SQLAlchemy, Alembic, Pydantic, JWT, bcrypt, Docker SDK
**Database:** PostgreSQL (asyncpg), Redis
**Auth:** GitHub OAuth (Ov23ligZpEMxoOjbXjof), JWT tokens, rate limiting
**Testing:** Docker sandbox, Playwright, HTML/CSS validation, secure code execution
**DevOps:** Turborepo, GitHub Actions, Husky, ESLint, Prettier, Ruff, Black
**Security:** Sandboxed execution, capability dropping, resource limits, no network access
